<h2> Overview </h2>
Zillow’s Zestimate home valuation has shaken up the U.S. real estate industry since first released 11 years ago.
A home is often the largest and most expensive purchase a person makes in his or her lifetime. Ensuring homeowners have a trusted way to monitor this asset is incredibly important. The Zestimate was created to give consumers as much information as possible about homes and the housing market, marking the first-time consumers had access to this type of home value information at no cost.
“Zestimates” are estimated home values based on 7.5 million statistical and machine learning models that analyze hundreds of data points on each property. And, by continually improving the median margin of error (from 14% at the onset to 5% today), Zillow has since become established as one of the largest, most trusted marketplaces for real estate information in the U.S. and a leading example of impactful machine learning.
My capstone project proposal is to replicate or write an even better Zestimate algorithm to estimate the value of listed properties on Zillow website. To keep the algorithm relevant in the future, I will create a pipeline to automate the process of ETL from Zillow website and feeding the algorithm with new extracted data.
I plan to do the automation using AWS and apache airflow. So far, I have been working on the database I found on a Kaggle competition to develop a ML algorithm to perform a Zestimate.
<h2> How to Run </h2>
<ol>
 <li> Clone this repository to your local computer.</li>
 <li> 

  [This](https://github.com/codingforentrepreneurs/Jupyter-x-Docker-on-Heroku) is the link which contains the steps to run a jupyter notebook using docker. The process can be used similarily for this project.
 
</li>
</ol>
